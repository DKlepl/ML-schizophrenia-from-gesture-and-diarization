---
title: "07 Prediction interpretation and hypothesis testing"
author: "Dominik Klepl"
date: "11/25/2018"
output: html_document
---

# Import functions
```{r}
pacman::p_load("caret", "DALEX", "tidyverse")
source("Scripts/modelling_fuctions.R")
```

# Hypothesis testing
Coordination models perform better than participant models. Compare the best models,

Load data and models
```{r}
p_data = caret_friendly(read.csv("clean_data/ML_data/Participant_boruta.csv"))
c_data = caret_friendly(read.csv("clean_data/ML_data/Coordination_featexp.csv"))

p_models = load_models("P")
c_models = load_models("C")

best_p = p_models[(startsWith(names(p_models),"boruta"))]
best_c = c_models[(startsWith(names(c_models), "featexp"))]

rm(p_models)
rm(c_models)
```

Hypothesis HOLDS!!!
```{r}
model_test_p = data.frame()
for (i in 1:length(best_p)) {
  model = best_p[[i]]
  one_cm = confusionMatrix(data=predict(model, p_data$X_test), reference = p_data$Y_test, mode="everything")
  overall = as.data.frame(t(as.data.frame(one_cm$overall)))
  byclass = as.data.frame(t(as.data.frame(one_cm$byClass)))
  one_model = cbind(overall, byclass)
  one_model$model = model$method
  model_test_p = rbind(model_test_p, one_model)
}


model_test_c = data.frame()
for (i in 1:length(best_c)) {
  model = best_c[[i]]
  one_cm = confusionMatrix(data=predict(model, c_data$X_test), reference = c_data$Y_test, mode="everything")
  overall = as.data.frame(t(as.data.frame(one_cm$overall)))
  byclass = as.data.frame(t(as.data.frame(one_cm$byClass)))
  one_model = cbind(overall, byclass)
  one_model$model = model$method
  model_test_c = rbind(model_test_c, one_model)
}

write.csv(model_test_p, "Model_evaluation/Test_performance_participant.csv", row.names = F)
write.csv(model_test_c, "Model_evaluation/Test_performance_coordination.csv", row.names = F)
```
    
# How accurate is the model if all samples from one participant are merged into one final prediction

Better make this into a function
```{r}
finalPrediction = function (which = c("C", "P"), model) {
  if (which == "C") {data = c_data}
  if (which == "P") {data = p_data}
  
  predictions = predict(model, data$X_test, type = "prob")
  predictions$ID = subset(data$no_model, set=="test")$ID
  predictions$diagnosis = data$Y_test
  predictions$diagnosis = ifelse(predictions$diagnosis=="Control", 0, 1)
  predictions$time = subset(data$no_model, set=="test")$time
  
  sum_pred = predictions %>% group_by(ID) %>% summarise(n_samples = n(), Schizophrenic=weighted.mean(x=Schizophrenic, w=time), diagnosis=mean(diagnosis))
  
  
  sum_pred$decision_s = ifelse(sum_pred$Schizophrenic>=0.5, "Schizophrenic", "Control")
  sum_pred$diagnosis = ifelse(sum_pred$diagnosis==1, "Schizophrenic", "Control")
  
  sum_pred$decision_s = as.factor(sum_pred$decision_s)
  sum_pred$diagnosis = as.factor(sum_pred$diagnosis)
  
  
  output = confusionMatrix(data=sum_pred$decision_s, reference = sum_pred$diagnosis, positive = "Schizophrenic")
  
  return(output)
}
```


For participant model - NO information rate = 0.5
```{r}
p_nn = finalPrediction("P", best_p$boruta_avNNet)[3:4]
p_bayes = finalPrediction("P", best_p$boruta_bayes)[3:4]
p_log = finalPrediction("P", best_p$boruta_logistic)[3:4]
p_rf = finalPrediction("P", best_p$boruta_rf)[3:4]
p_xgb = finalPrediction("P", best_p$boruta_xboost)[3:4]

average_prediction_p = data.frame(Model=c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost"))
overall = as.data.frame(rbind(p_nn$overall, p_bayes$overall, p_log$overall, p_rf$overall, p_xgb$overall))
byclass = as.data.frame(rbind(p_nn$byClass, p_bayes$byClass, p_log$byClass, p_rf$byClass, p_xgb$byClass))

average_prediction_p = cbind(average_prediction_p, overall, byclass)
average_prediction_p = average_prediction_p[,c(-4:-8, -11:-19)]

write.csv(average_prediction_p, "Model_evaluation/Averaged_prediction_participant.csv", row.names = F)
```

Coordination model - No information rate = 0.5
```{r}
c_nn = finalPrediction("C", best_c$featexp_avNNet)[3:4]
c_bayes = finalPrediction("C", best_c$featexp_bayes)[3:4]
c_log = finalPrediction("C", best_c$featexp_logistic)[3:4]
c_rf = finalPrediction("C", best_c$featexp_rf)[3:4]
c_xgb = finalPrediction("C", best_c$featexp_xboost)[3:4]

average_prediction_c = data.frame(Model=c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost"))
overall = as.data.frame(rbind(c_nn$overall, c_bayes$overall, c_log$overall, c_rf$overall, c_xgb$overall))
byclass = as.data.frame(rbind(c_nn$byClass, c_bayes$byClass, c_log$byClass, c_rf$byClass, c_xgb$byClass))

average_prediction_c = cbind(average_prediction_c, overall, byclass)
average_prediction_c = average_prediction_c[,c(-4:-8, -11:-19)]

write.csv(average_prediction_c, "Model_evaluation/Averaged_prediction_coordination.csv", row.names = F)
```

These results indicate that accuracy may be increasing in samples taken from later in the interview.

# Does accuracy increase in time?
Hypothesis: 
    - in participant - NO
    - in coordination - YES, coordination systems emerge over time


```{r}
results_c = data.frame(ID = subset(c_data$no_model, set=="test")$ID,
                       diagnosis = c_data$Y_test,
                       time = subset(c_data$no_model, set=="test")$time)
results_p = data.frame(ID = subset(p_data$no_model, set=="test")$ID,
                       diagnosis = p_data$Y_test,
                       time = subset(p_data$no_model, set=="test")$time)

prediction_c = predict(best_c$featexp_bayes, c_data$X_test, type = "prob")
prediction_p = predict(best_p$boruta_bayes, p_data$X_test, type = "prob")

results_c = cbind(results_c, prediction_c)
results_p = cbind(results_p ,prediction_p)

results_c$diagnosis = ifelse(results_c$diagnosis=="Control", 0, 1)
results_c$rmse = ifelse(results_c$diagnosis==0, 1-results_c$Control, 1-results_c$Schizophrenic)

results_p$diagnosis = ifelse(results_p$diagnosis=="Control", 0, 1)
results_p$rmse = ifelse(results_p$diagnosis==0, 1-results_p$Control, 1-results_p$Schizophrenic)

results_c$model = "coordination"
results_p$model = "participant"

results = rbind(results_c, results_p)

library(lmerTest)
acc_time = lmer(rmse ~ time + model +(1|ID), results)
acc_model = lmer(rmse ~ model +(1|ID), results)

summary(acc_time)
summary(acc_model)

#acc_time model shows both better performance of coordination model and that there is no significant change in performance over time
model_comparison = summary(acc_time)
model_comparison = round(model_comparison$coefficients,3)
model_comparison

write.csv(model_comparison, "Model_evaluation/Coordination_vs_participant.csv", row.names = F)
```

# Prediction understanding with DALEX

It doesn't make sense to try to interpret the participant models because their performance on the test data isn't significantly higher than no-information rate.


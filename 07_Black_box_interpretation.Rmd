---
title: "07 Prediction interpretation and hypothesis testing"
author: "Dominik Klepl"
date: "11/25/2018"
output: html_document
---

# Import functions
```{r}
pacman::p_load("caret", "DALEX", "tidyverse", "pROC", "grid", "gridExtra", "ggthemes")
source("Scripts/modelling_fuctions.R")
```

# Hypothesis testing
Coordination models perform better than participant models. Compare the best models,

Load data and models
```{r}
p_data = caret_friendly(read.csv("clean_data/ML_data/Participant_boruta.csv"))
c_data = caret_friendly(read.csv("clean_data/ML_data/Coordination_featexp.csv"))

p_models = load_models("P")
c_models = load_models("C")

best_p = p_models[(startsWith(names(p_models),"boruta"))]
best_c = c_models[(startsWith(names(c_models), "featexp"))]

rm(p_models)
rm(c_models)
```

Hypothesis HOLDS!!!

```{r}
model_test_p = data.frame()
for (i in 1:length(best_p)) {
  model = best_p[[i]]
  one_cm = confusionMatrix(data=predict(model, p_data$X_test), reference = p_data$Y_test, mode="everything")
  auc = auc(p_data$Y_test, predict(model, p_data$X_test, type = "prob")[,1])
  overall = as.data.frame(t(as.data.frame(one_cm$overall)))
  byclass = as.data.frame(t(as.data.frame(one_cm$byClass)))
  one_model = cbind(auc,overall, byclass)
  one_model$model = model$method
  model_test_p = rbind(model_test_p, one_model)
}


model_test_c = data.frame()
for (i in 1:length(best_c)) {
  model = best_c[[i]]
  one_cm = confusionMatrix(data=predict(model, c_data$X_test), reference = c_data$Y_test, mode="everything")
  auc = auc(c_data$Y_test, predict(model, c_data$X_test, type = "prob")[,1])
  overall = as.data.frame(t(as.data.frame(one_cm$overall)))
  byclass = as.data.frame(t(as.data.frame(one_cm$byClass)))
  one_model = cbind(auc, overall, byclass)
  one_model$model = model$method
  model_test_c = rbind(model_test_c, one_model)
}

write.csv(model_test_p, "Model_evaluation/Test_performance_participant.csv", row.names = F)
write.csv(model_test_c, "Model_evaluation/Test_performance_coordination.csv", row.names = F)

results_all = rbind(model_test_p, model_test_c)
results_all$set = c(rep("Participant", 5), rep("Coordination", 5))

auc_test = ggplot(results_all, aes(x=model, y=auc, color=set))+
  geom_point(size=5)+
  theme_few()+
  scale_color_few()+
  labs(y="AUC", x=NULL)+
  guides(color=F)
auc_test

sens_test = ggplot(results_all, aes(x=model, y=Sensitivity, color=set))+
  geom_point(size=5)+
  theme_few()+
  scale_color_few()+
  labs(y="Sensitivity", x=NULL)+
  guides(color=F)
sens_test

spec_test = ggplot(results_all, aes(x=model, y=Specificity, color=set))+
  geom_point(size=5)+
  theme_few()+
  scale_color_few()+
  labs(y="Specificity", x=NULL)
spec_test

ggsave("Model_evaluation/AUC_validation.jpg", auc_test, width = 7, height = 3)


performance_all = grid.arrange(auc_test, sens_test, spec_test, top=textGrob("Performance of top 10 models on validation data", gp=gpar(fontsize=12, font=3)))

ggsave("Model_evaluation/Validation_performance.jpg", performance_all, width = 7, height = 5)
```
    
# How accurate is the model if all samples from one participant are merged into one final prediction

Better make this into a function
```{r}
finalPrediction_noweights = function (which = c("C", "P"), model) {
  if (which == "C") {data = c_data}
  if (which == "P") {data = p_data}
  
  predictions = predict(model, data$X_test, type = "prob")
  predictions$ID = subset(data$no_model, set=="test")$ID
  predictions$diagnosis = data$Y_test
  predictions$diagnosis = ifelse(predictions$diagnosis=="Control", 0, 1)
  predictions$time = subset(data$no_model, set=="test")$time
  
  sum_pred = predictions %>% group_by(ID) %>% summarise(n_samples = n(), Schizophrenic=mean(x=Schizophrenic), diagnosis=mean(diagnosis))
  auc = auc(sum_pred$diagnosis, sum_pred$Schizophrenic)
  
  sum_pred$decision_s = ifelse(sum_pred$Schizophrenic>=0.5, "Schizophrenic", "Control")
  sum_pred$diagnosis = ifelse(sum_pred$diagnosis==1, "Schizophrenic", "Control")
  
  sum_pred$decision_s = as.factor(sum_pred$decision_s)
  sum_pred$diagnosis = as.factor(sum_pred$diagnosis)
  
  
  cM = confusionMatrix(data=sum_pred$decision_s, reference = sum_pred$diagnosis, positive = "Schizophrenic")
  
  overall = as.data.frame(rbind(cM$overall))
  byclass = as.data.frame(rbind(cM$byClass))
  
  perf = cbind(auc, overall, byclass)
  
  return(perf)
}

finalPrediction_weights = function (which = c("C", "P"), model) {
  if (which == "C") {data = c_data}
  if (which == "P") {data = p_data}
  
  predictions = predict(model, data$X_test, type = "prob")
  predictions$ID = subset(data$no_model, set=="test")$ID
  predictions$diagnosis = data$Y_test
  predictions$diagnosis = ifelse(predictions$diagnosis=="Control", 0, 1)
  predictions$time = subset(data$no_model, set=="test")$time
  
  sum_pred = predictions %>% group_by(ID) %>% summarise(n_samples = n(), Schizophrenic=weighted.mean(x=Schizophrenic, w=time), diagnosis=mean(diagnosis))
  auc = auc(sum_pred$diagnosis, sum_pred$Schizophrenic)
  
  sum_pred$decision_s = ifelse(sum_pred$Schizophrenic>=0.5, "Schizophrenic", "Control")
  sum_pred$diagnosis = ifelse(sum_pred$diagnosis==1, "Schizophrenic", "Control")
  
  sum_pred$decision_s = as.factor(sum_pred$decision_s)
  sum_pred$diagnosis = as.factor(sum_pred$diagnosis)
  
  
  cM = confusionMatrix(data=sum_pred$decision_s, reference = sum_pred$diagnosis, positive = "Schizophrenic")
  
  overall = as.data.frame(rbind(cM$overall))
  byclass = as.data.frame(rbind(cM$byClass))
  
  perf = cbind(auc, overall, byclass)
  
  return(perf)
}
```


No weights mean
```{r}
p_nn = finalPrediction_noweights("P", best_p$boruta_avNNet)
p_bayes = finalPrediction_noweights("P", best_p$boruta_bayes)
p_log = finalPrediction_noweights("P", best_p$boruta_logistic)
p_rf = finalPrediction_noweights("P", best_p$boruta_rf)
p_xgb = finalPrediction_noweights("P", best_p$boruta_xboost)

average_prediction_p = rbind(p_nn, p_bayes, p_log, p_rf, p_xgb)
average_prediction_p$Model = c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost")
average_prediction_p$set = "PD"

c_nn = finalPrediction_noweights("C", best_c$featexp_avNNet)
c_bayes = finalPrediction_noweights("C", best_c$featexp_bayes)
c_log = finalPrediction_noweights("C", best_c$featexp_logistic)
c_rf = finalPrediction_noweights("C", best_c$featexp_rf)
c_xgb = finalPrediction_noweights("C", best_c$featexp_xboost)

average_prediction_c = rbind(c_nn, c_bayes, c_log, c_rf, c_xgb)
average_prediction_c$Model = c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost")

average_prediction_c$set = "CD"

average_prediction_mean = rbind(average_prediction_p, average_prediction_c)
average_prediction_mean[,1:19] = round(average_prediction_mean[,1:19], 3)

write.csv(average_prediction_mean, "Model_evaluation/Average_prediction_noweights.csv", row.names = F)
```

Weighted with time
```{r}
p_nn = finalPrediction_weights("P", best_p$boruta_avNNet)
p_bayes = finalPrediction_weights("P", best_p$boruta_bayes)
p_log = finalPrediction_weights("P", best_p$boruta_logistic)
p_rf = finalPrediction_weights("P", best_p$boruta_rf)
p_xgb = finalPrediction_weights("P", best_p$boruta_xboost)

average_prediction_p = rbind(p_nn, p_bayes, p_log, p_rf, p_xgb)
average_prediction_p$Model = c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost")
average_prediction_p$set = "PD"

c_nn = finalPrediction_weights("C", best_c$featexp_avNNet)
c_bayes = finalPrediction_weights("C", best_c$featexp_bayes)
c_log = finalPrediction_weights("C", best_c$featexp_logistic)
c_rf = finalPrediction_weights("C", best_c$featexp_rf)
c_xgb = finalPrediction_weights("C", best_c$featexp_xboost)

average_prediction_c = rbind(c_nn, c_bayes, c_log, c_rf, c_xgb)
average_prediction_c$Model = c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost")

average_prediction_c$set = "CD"

average_prediction_weighted = rbind(average_prediction_p, average_prediction_c)
average_prediction_weighted[,1:19] = round(average_prediction_weighted[,1:19], 3)

write.csv(average_prediction_weighted, "Model_evaluation/Average_prediction_weighted.csv", row.names = F)
```

These results indicate that accuracy may be increasing in samples taken from later in the interview.

# Does accuracy increase in time?
Hypothesis: 
    - in participant - NO
    - in coordination - YES, coordination systems emerge over time

Use best participant model and the worst coordination model to get stronger evidence of main hypothesis
```{r}
results_c = data.frame(ID = subset(c_data$no_model, set=="test")$ID,
                       diagnosis = c_data$Y_test,
                       time = subset(c_data$no_model, set=="test")$time)
results_p = data.frame(ID = subset(p_data$no_model, set=="test")$ID,
                       diagnosis = p_data$Y_test,
                       time = subset(p_data$no_model, set=="test")$time)

prediction_c = predict(best_c$featexp_xboost, c_data$X_test, type = "prob")
prediction_p = predict(best_p$boruta_xboost, p_data$X_test, type = "prob")

results_c = cbind(results_c, prediction_c)
results_p = cbind(results_p ,prediction_p)

results_c$diagnosis = ifelse(results_c$diagnosis=="Control", 0, 1)
results_c$rmse = ifelse(results_c$diagnosis==0, 1-results_c$Control, 1-results_c$Schizophrenic)

results_p$diagnosis = ifelse(results_p$diagnosis=="Control", 0, 1)
results_p$rmse = ifelse(results_p$diagnosis==0, 1-results_p$Control, 1-results_p$Schizophrenic)

results_c$set = "coordination"
results_p$set = "participant"

results = rbind(results_c, results_p)
results$model = "xgb"

results_all = rbind(results_all, results)

#test participant model
time_participant = lmer(rmse ~ time +(1|ID), results_p)
time_coordination = lmer(rmse ~ time +(1|ID), results_c)

summary(time_participant)
summary(time_coordination)

library(lmerTest)
acc_model = lmer(rmse ~ set +(1|ID), results_all)

summary(acc_model)



#acc_time model shows both better performance of coordination model and that there is no significant change in performance over time
model_comparison = summary(acc_model)
model_comparison = round(model_comparison$coefficients,3)
model_comparison

write.csv(model_comparison, "Model_evaluation/Coordination_vs_participant.csv")
```

Result - no increase in performance over time

# Prediction understanding with DALEX

It doesn't make sense to try to interpret the participant models because their performance on the test data much higher than random guess.

## Coordination models interpretation
We'll look inside of all 5 models. Compare the decision patterns. Maybe also residuals.

Import libraries, models and testing data.
```{r}
library(DALEX)
library(caret)
library(breakDown)
library(ggthemes)
source("Scripts/modelling_fuctions.R")

models = load_models("C")
models = models[(startsWith(names(models), "featexp"))]
data = read.csv("clean_data/ML_data/Coordination_featexp.csv")
data = subset(data, set=="test")
data = data[,c(-1, -3:-5)]
```

### Create model explainers
```{r}
p_fun <- function(object, newdata){
  predict(object, newdata=newdata, type="prob")[,1]
}

#DAlEX requires the target to be numeric
data$diagnosis = ifelse(data$diagnosis=="Control", 0, 1)

#create explainers
expl_nn = explain(models$featexp_avNNet, y=data[,1], data=data[,-1], predict_function = p_fun, label = "avNNet")
expl_bayes = explain(models$featexp_bayes, y=data[,1], data=data[,-1], predict_function = p_fun, label = "Naive Bayes")
expl_log = explain(models$featexp_logistic, y=data[,1], data=data[,-1], predict_function = p_fun, label = "PLR")
expl_rf = explain(models$featexp_rf, y=data[,1], data=data[,-1], predict_function = p_fun, label = "Random Forest")
expl_xgb = explain(models$featexp_xboost, y=data[,1], data=data[,-1], predict_function = p_fun, label = "XGBoost")
```

### Residual Analysis
Calculate residuals = difference between prediction and true value
```{r}
#calculate residuals - difference between prediction and true value
performance_nn = model_performance(expl_nn)
performance_bayes = model_performance(expl_bayes)
performance_log = model_performance(expl_log)
performance_rf = model_performance(expl_rf)
performance_xgb = model_performance(expl_xgb)

#plot the residuals
residual_distribution = plot(performance_nn, 
     performance_bayes, 
     performance_log, 
     performance_rf, 
     performance_xgb, geom = "boxplot", outliers=1)+
  theme_few()+
  scale_fill_few()+
  labs(title = "Distribution of residuals", x="Residuals")+
  guides(fill=F)

residual_distribution

ggsave("Model_interpretation/Residuals.jpg", width = 7, height = 4)
```

### Feature importance
Using permutation and ROC as evaluation metric

Custom function to run a 1000-repeated permutation importance
```{r}
variable_importance_rep = function(model, n) {
  imps=data.frame()
  for (i in 1:n) {
    imp = variable_importance(model, n_sample = -1)
    imps = rbind(imps, imp)
  }
  imps = imps %>% group_by(variable) %>% summarise(dropout_loss=mean(dropout_loss))
  imps$label=rep(model$label,12)
  class(imps)=c("variable_importance_explainer", "data.frame" )
  return(imps)
}
```

```{r}
imp_nn = variable_importance_rep(expl_nn, n=1000)
imp_bayes = variable_importance_rep(expl_bayes, n=1000)
imp_log = variable_importance_rep(expl_log, n=1000)
imp_rf = variable_importance_rep(expl_rf, n=1000)
imp_xgb = variable_importance_rep(expl_xgb, n=1000)

imp_plot = plot(imp_nn, imp_bayes, imp_log, imp_rf, imp_xgb, max_vars = 20)+
  theme_few()+
  labs(title = "Feature Importance")
imp_plot

ggsave("Model_interpretation/Feature_importance.jpg", imp_plot, width = 10, height = 8)
```

### Patterns in the data

IQR diff
```{r}
#important in avnnet, bayes and plr
resp1_nn = variable_response(expl_nn, variable = "iqr_diff", type="ale", prob=T)
resp1_bayes = variable_response(expl_bayes, variable = "iqr_diff",type = "ale")
resp1_log = variable_response(expl_log, variable = "iqr_diff",type = "ale")
resp1_rf = variable_response(expl_rf, variable = "iqr_diff",type = "ale")
resp1_xgb = variable_response(expl_xgb, variable = "iqr_diff",type = "ale")

plot_iqr = plot(resp1_nn, resp1_bayes, resp1_log, resp1_rf, resp1_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of iqr_diff")+
  scale_color_few()
plot_iqr


plot(single_prediction(expl_bayes, data[54,], direction="up"))

ggsave("Model_interpretation/IQR_pdp.jpg", plot_iqr, width = 7, height = 4)
```

sum diff
```{r}
#important for avnnet, 
resp2_nn = variable_response(expl_nn, variable = "sum_diff", type="ale")
resp2_bayes = variable_response(expl_bayes, variable = "sum_diff", type="ale")
resp2_log = variable_response(expl_log, variable = "sum_diff", type="ale")
resp2_rf = variable_response(expl_rf, variable = "sum_diff", type="ale")
resp2_xgb = variable_response(expl_xgb, variable = "sum_diff", type="ale")


plot_sum = plot(resp2_nn, resp2_bayes, resp2_log, resp2_rf, resp2_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of sum_diff")
plot_sum

ggsave("Model_interpretation/sum_pdp.jpg", plot_sum, width = 7, height = 4)
```

median_diff
```{r}
#important for avnnet, 
resp3_nn = variable_response(expl_nn, variable = "median_diff", type="ale")
resp3_bayes = variable_response(expl_bayes, variable = "median_diff", type="ale")
resp3_log = variable_response(expl_log, variable = "median_diff", type="ale")
resp3_rf = variable_response(expl_rf, variable = "median_diff", type="ale")
resp3_xgb = variable_response(expl_xgb, variable = "median_diff", type="ale")


plot_median = plot(resp3_nn, resp3_bayes, resp3_log, resp3_rf, resp3_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of median_diff")
plot_median

ggsave("Model_interpretation/median_pdp.jpg", plot_median, width = 7, height = 4)
```

maxL
```{r}
#important for avnnet, 
resp4_nn = variable_response(expl_nn, variable = "maxL", type="ale")
resp4_bayes = variable_response(expl_bayes, variable = "maxL", type="ale")
resp4_log = variable_response(expl_log, variable = "maxL", type="ale")
resp4_rf = variable_response(expl_rf, variable = "maxL", type="ale")
resp4_xgb = variable_response(expl_xgb, variable = "maxL", type="ale")


plot_maxL = plot(resp4_nn, resp4_bayes, resp4_log, resp4_rf, resp4_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of maxL")
plot_maxL

ggsave("Model_interpretation/maxL_pdp.jpg", plot_maxL, width = 7, height = 4)
```

mad_diff
```{r}
#important for avnnet, 
resp5_nn = variable_response(expl_nn, variable = "mad_diff", type="ale")
resp5_bayes = variable_response(expl_bayes, variable = "mad_diff", type="ale")
resp5_log = variable_response(expl_log, variable = "mad_diff", type="ale")
resp5_rf = variable_response(expl_rf, variable = "mad_diff", type="ale")
resp5_xgb = variable_response(expl_xgb, variable = "mad_diff", type="ale")


plot_mad = plot(resp5_nn, resp5_bayes, resp5_log, resp5_rf, resp5_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of mad_diff")
plot_mad

ggsave("Model_interpretation/mad_pdp.jpg", plot_mad, width = 7, height = 4)
```

LAM_diff
```{r}
#important for avnnet, 
resp6_nn = variable_response(expl_nn, variable = "LAM_diff", type="ale")
resp6_bayes = variable_response(expl_bayes, variable = "LAM_diff", type="ale")
resp6_log = variable_response(expl_log, variable = "LAM_diff", type="ale")
resp6_rf = variable_response(expl_rf, variable = "LAM_diff", type="ale")
resp6_xgb = variable_response(expl_xgb, variable = "LAM_diff", type="ale")


plot_LAM = plot(resp6_nn, resp6_bayes, resp6_log, resp6_rf, resp6_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of LAM_diff")
plot_LAM

ggsave("Model_interpretation/LAM_pdp.jpg", plot_LAM, width = 7, height = 4)
```

var_diff
```{r}
#important for avnnet, 
resp7_nn = variable_response(expl_nn, variable = "var_diff", type="ale")
resp7_bayes = variable_response(expl_bayes, variable = "var_diff", type="ale")
resp7_log = variable_response(expl_log, variable = "var_diff", type="ale")
resp7_rf = variable_response(expl_rf, variable = "var_diff", type="ale")
resp7_xgb = variable_response(expl_xgb, variable = "var_diff", type="ale")


plot_var = plot(resp7_nn, resp7_bayes, resp7_log, resp7_rf, resp7_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of var_diff")
plot_var

ggsave("Model_interpretation/var_pdp.jpg", plot_var, width = 7, height = 4)
```

max_diff
```{r}
resp8_nn = variable_response(expl_nn, variable = "max_diff", type="ale")
resp8_bayes = variable_response(expl_bayes, variable = "max_diff", type="ale")
resp8_log = variable_response(expl_log, variable = "max_diff", type="ale")
resp8_rf = variable_response(expl_rf, variable = "max_diff", type="ale")
resp8_xgb = variable_response(expl_xgb, variable = "max_diff", type="ale")


plot_max = plot(resp8_nn, resp8_bayes, resp8_log, resp8_rf, resp8_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of max_diff")
plot_max

ggsave("Model_interpretation/max_pdp.jpg", plot_max, width = 8, height = 4)
```


range_diff
```{r}
resp9_nn = variable_response(expl_nn, variable = "range_diff", type="ale")
resp9_bayes = variable_response(expl_bayes, variable = "range_diff", type="ale")
resp9_log = variable_response(expl_log, variable = "range_diff", type="ale")
resp9_rf = variable_response(expl_rf, variable = "range_diff", type="ale")
resp9_xgb = variable_response(expl_xgb, variable = "range_diff", type="ale")


plot_range = plot(resp9_nn, resp9_bayes, resp9_log, resp9_rf, resp9_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of range_diff")
plot_range

ggsave("Model_interpretation/range_pdp.jpg", plot_range, width = 8, height = 4)
```

sd_diff
```{r}
resp10_nn = variable_response(expl_nn, variable = "sd_diff", type="ale")
resp10_bayes = variable_response(expl_bayes, variable = "sd_diff", type="ale")
resp10_log = variable_response(expl_log, variable = "sd_diff", type="ale")
resp10_rf = variable_response(expl_rf, variable = "sd_diff", type="ale")
resp10_xgb = variable_response(expl_xgb, variable = "sd_diff", type="ale")


plot_sd = plot(resp10_nn, resp10_bayes, resp10_log, resp10_rf, resp10_xgb)+
  theme_few()+
  guides(shape=F)+
  labs(title = "ALE of sd_diff")
plot_sd

ggsave("Model_interpretation/sd_pdp.jpg", plot_sd, width = 8, height = 4)
```

## Single prediction breakdown
```{r}
rownames(data)=NULL
pred = predict(models$featexp_avNNet, data, type = "prob")
pred$true = data$diagnosis
rownames(pred)=NULL

#give example of 100% schizo and correct prediction
schizo = data[358,]
schizo[,2:11]=round(schizo[,2:11], 3)
schizo_break = prediction_breakdown(expl_nn, schizo[,-1])
S_break = plot(schizo_break)+
  theme_few()+
  guides(fill=F)+
  labs(subtitle ="Diagnosis: Schizophrenia")
ggsave("Model_interpretation/breakdown_patient.jpg", S_break)

#example of definitely control
ctrl = data[137,]
ctrl[,2:11]=round(ctrl[,2:11], 3)
ctrl_break = prediction_breakdown(expl_nn, ctrl[,-1])
C_break = plot(ctrl_break)+
  theme_few()+
  guides(fill=F)+
  labs(subtitle="Diagnosis: Healthy")

library(gridExtra)
library(grid)
breakdown_both = grid.arrange(S_break, C_break, ncol=2, top=textGrob("Breakdown of predictions", gp=gpar(fontsize=10, font=3)))
ggsave("Model_interpretation/Breakdown_example.jpg", breakdown_both, width = 8, height = 3)
```


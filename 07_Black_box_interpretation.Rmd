---
title: "07 Prediction interpretation and hypothesis testing"
author: "Dominik Klepl"
date: "11/25/2018"
output: html_document
---

# Import functions
```{r}
pacman::p_load("caret", "DALEX", "tidyverse", "pROC")
source("Scripts/modelling_fuctions.R")
```

# Hypothesis testing
Coordination models perform better than participant models. Compare the best models,

Load data and models
```{r}
p_data = caret_friendly(read.csv("clean_data/ML_data/Participant_boruta.csv"))
c_data = caret_friendly(read.csv("clean_data/ML_data/Coordination_featexp.csv"))

p_models = load_models("P")
c_models = load_models("C")

best_p = p_models[(startsWith(names(p_models),"boruta"))]
best_c = c_models[(startsWith(names(c_models), "featexp"))]

rm(p_models)
rm(c_models)
```

Hypothesis HOLDS!!!
```{r}
model_test_p = data.frame()
for (i in 1:length(best_p)) {
  model = best_p[[i]]
  one_cm = confusionMatrix(data=predict(model, p_data$X_test), reference = p_data$Y_test, mode="everything")
  auc = auc(p_data$Y_test, predict(model, p_data$X_test, type = "prob")[,1])
  overall = as.data.frame(t(as.data.frame(one_cm$overall)))
  byclass = as.data.frame(t(as.data.frame(one_cm$byClass)))
  one_model = cbind(auc,overall, byclass)
  one_model$model = model$method
  model_test_p = rbind(model_test_p, one_model)
}


model_test_c = data.frame()
for (i in 1:length(best_c)) {
  model = best_c[[i]]
  one_cm = confusionMatrix(data=predict(model, c_data$X_test), reference = c_data$Y_test, mode="everything")
  auc = auc(c_data$Y_test, predict(model, c_data$X_test, type = "prob")[,1])
  overall = as.data.frame(t(as.data.frame(one_cm$overall)))
  byclass = as.data.frame(t(as.data.frame(one_cm$byClass)))
  one_model = cbind(auc, overall, byclass)
  one_model$model = model$method
  model_test_c = rbind(model_test_c, one_model)
}

write.csv(model_test_p, "Model_evaluation/Test_performance_participant.csv", row.names = F)
write.csv(model_test_c, "Model_evaluation/Test_performance_coordination.csv", row.names = F)
```
    
# How accurate is the model if all samples from one participant are merged into one final prediction

Better make this into a function
```{r}
finalPrediction = function (which = c("C", "P"), model) {
  if (which == "C") {data = c_data}
  if (which == "P") {data = p_data}
  
  predictions = predict(model, data$X_test, type = "prob")
  predictions$ID = subset(data$no_model, set=="test")$ID
  predictions$diagnosis = data$Y_test
  predictions$diagnosis = ifelse(predictions$diagnosis=="Control", 0, 1)
  predictions$time = subset(data$no_model, set=="test")$time
  
  sum_pred = predictions %>% group_by(ID) %>% summarise(n_samples = n(), Schizophrenic=weighted.mean(x=Schizophrenic, w=time), diagnosis=mean(diagnosis))
  auc = auc(sum_pred$diagnosis, sum_pred$Schizophrenic)
  
  sum_pred$decision_s = ifelse(sum_pred$Schizophrenic>=0.5, "Schizophrenic", "Control")
  sum_pred$diagnosis = ifelse(sum_pred$diagnosis==1, "Schizophrenic", "Control")
  
  sum_pred$decision_s = as.factor(sum_pred$decision_s)
  sum_pred$diagnosis = as.factor(sum_pred$diagnosis)
  
  
  cM = confusionMatrix(data=sum_pred$decision_s, reference = sum_pred$diagnosis, positive = "Schizophrenic")
  
  overall = as.data.frame(rbind(cM$overall))
  byclass = as.data.frame(rbind(cM$byClass))
  
  perf = cbind(auc, overall, byclass)
  
  return(perf)
}
```


For participant model - NO information rate = 0.5
```{r}
p_nn = finalPrediction("P", best_p$boruta_avNNet)
p_bayes = finalPrediction("P", best_p$boruta_bayes)
p_log = finalPrediction("P", best_p$boruta_logistic)
p_rf = finalPrediction("P", best_p$boruta_rf)
p_xgb = finalPrediction("P", best_p$boruta_xboost)

average_prediction_p = rbind(p_nn, p_bayes, p_log, p_rf, p_xgb)
average_prediction_p$Model = c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost")

write.csv(average_prediction_p, "Model_evaluation/Averaged_prediction_participant.csv", row.names = F)
```

Coordination model - No information rate = 0.5
```{r}
c_nn = finalPrediction("C", best_c$featexp_avNNet)
c_bayes = finalPrediction("C", best_c$featexp_bayes)
c_log = finalPrediction("C", best_c$featexp_logistic)
c_rf = finalPrediction("C", best_c$featexp_rf)
c_xgb = finalPrediction("C", best_c$featexp_xboost)

average_prediction_c = rbind(c_nn, c_bayes, c_log, c_rf, c_xgb)
average_prediction_c$Model = c("avNNet", "Naive Bayes", "Penalized Logistic Regression", "Random Forest", "XGBoost")

write.csv(average_prediction_c, "Model_evaluation/Averaged_prediction_coordination.csv", row.names = F)
```

These results indicate that accuracy may be increasing in samples taken from later in the interview.

# Does accuracy increase in time?
Hypothesis: 
    - in participant - NO
    - in coordination - YES, coordination systems emerge over time


```{r}
results_c = data.frame(ID = subset(c_data$no_model, set=="test")$ID,
                       diagnosis = c_data$Y_test,
                       time = subset(c_data$no_model, set=="test")$time)
results_p = data.frame(ID = subset(p_data$no_model, set=="test")$ID,
                       diagnosis = p_data$Y_test,
                       time = subset(p_data$no_model, set=="test")$time)

prediction_c = predict(best_c$featexp_bayes, c_data$X_test, type = "prob")
prediction_p = predict(best_p$boruta_bayes, p_data$X_test, type = "prob")

results_c = cbind(results_c, prediction_c)
results_p = cbind(results_p ,prediction_p)

results_c$diagnosis = ifelse(results_c$diagnosis=="Control", 0, 1)
results_c$rmse = ifelse(results_c$diagnosis==0, 1-results_c$Control, 1-results_c$Schizophrenic)

results_p$diagnosis = ifelse(results_p$diagnosis=="Control", 0, 1)
results_p$rmse = ifelse(results_p$diagnosis==0, 1-results_p$Control, 1-results_p$Schizophrenic)

results_c$model = "coordination"
results_p$model = "participant"

results = rbind(results_c, results_p)

library(lmerTest)
acc_time = lmer(rmse ~ time + model +(1|ID), results)
acc_model = lmer(rmse ~ model +(1|ID), results)

summary(acc_time)
summary(acc_model)

#acc_time model shows both better performance of coordination model and that there is no significant change in performance over time
model_comparison = summary(acc_time)
model_comparison = round(model_comparison$coefficients,3)
model_comparison

write.csv(model_comparison, "Model_evaluation/Coordination_vs_participant.csv", row.names = F)
```

Result - no increase in performance over time

# Prediction understanding with DALEX

It doesn't make sense to try to interpret the participant models because their performance on the test data isn't significantly higher than no-information rate.

